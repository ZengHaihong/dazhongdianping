{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 整理程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import os.path\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException,WebDriverException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from requests.exceptions import ProxyError,ConnectionError,Timeout,HTTPError\n",
    "import itertools\n",
    "import random\n",
    "from lxml import etree\n",
    "\n",
    "\n",
    "# 设置请求头类\n",
    "class GetHeaders(object):\n",
    "    user_agent_list = [\n",
    "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 \"\n",
    "        \"(KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1\",\n",
    "        \"Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 \"\n",
    "        \"(KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 \"\n",
    "        \"(KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 \"\n",
    "        \"(KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 \"\n",
    "        \"(KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1\",\n",
    "        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 \"\n",
    "        \"(KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 \"\n",
    "        \"(KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 \"\n",
    "        \"(KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\n",
    "        \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 \"\n",
    "        \"(KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 \"\n",
    "        \"(KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 \"\n",
    "        \"(KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 \"\n",
    "        \"(KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 \"\n",
    "        \"(KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 \"\n",
    "        \"(KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 \"\n",
    "        \"(KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 \"\n",
    "        \"(KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3\",\n",
    "        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 \"\n",
    "        \"(KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 \"\n",
    "        \"(KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24\",\n",
    "        'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36'\n",
    "       ]\n",
    "\n",
    "    def getHeaders(self):\n",
    "        headers={\n",
    "         \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
    "         \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "         \"Accept-Language\": \"zh-CN,zh;q=0.8\",\n",
    "         \"Connection\": \"keep-alive\",\n",
    "         \"Content-Type\":\"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "         'User-Agent':random.choice(self.user_agent_list),\n",
    "        }\n",
    "        return headers\n",
    "\n",
    "    \n",
    "###############################################\n",
    "##生成一个ip池\n",
    "class Ip_pool():\n",
    "    '''\n",
    "    这是一个获取可用的ip池的类\n",
    "    '''\n",
    "    def __init__(self,ip_url_ls= ['http://www.xicidaili.com/nn/',\n",
    "                                 'http://www.xicidaili.com/nt/',\n",
    "                                 'http://www.xicidaili.com/wn/',\n",
    "                                 'http://www.xicidaili.com/wt/']):\n",
    "        self.ip_url_ls = ip_url_ls\n",
    "        \n",
    "        \n",
    "    def check_chinese(self,check_str):\n",
    "        zhPattern = re.compile(u'[\\u4e00-\\u9fa5]+')\n",
    "        match = zhPattern.search(check_str)\n",
    "        if match:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def visit_url(self,ip_url,prox_ip=None):\n",
    "        #headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.103 Safari/537.36\"}\n",
    "        headers = GetHeaders().getHeaders()\n",
    "        print(headers)\n",
    "        is_continue = True\n",
    "        while is_continue:\n",
    "            try:\n",
    "                if prox_ip is None:\n",
    "                    res = requests.get(ip_url,headers = headers)  #访问url，不设代理ip访问\n",
    "                else:\n",
    "                    http = prox_ip[0]\n",
    "                    ip = http+\"://\"+prox_ip[1]\n",
    "                    proxies={http:ip}\n",
    "                    res = requests.get(self.ip_url,headers = headers,proxies = proxies) #设代理ip访问\n",
    "                html =  res.content.decode('utf-8')\n",
    "                soup  =  BeautifulSoup(html,'lxml')\n",
    "                is_continue = False \n",
    "            \n",
    "            except HTTPError as e:\n",
    "                print(\"断网\")\n",
    "                time.sleep(2)\n",
    "\n",
    "            except Timeout as e:\n",
    "                print(\"请求超时\")\n",
    "                time.sleep(2)\n",
    "\n",
    "            except ConnectionError as e:\n",
    "                print(\"访问被拒\")\n",
    "                is_continue = True\n",
    "                time.sleep(2)\n",
    "\n",
    "        return soup\n",
    "\n",
    "\n",
    "    #*******获取ip信息**********\n",
    "    def get_iplist(self,soup):\n",
    "\n",
    "        '''\n",
    "        功能：对解析后的网页进行清洗，获得目标变量\n",
    "\n",
    "        参数\n",
    "        ----\n",
    "        soup：BeautifulSoup对象，网页元素经过解析后的对象，包含了ip、端口号以及其他信息。\n",
    "\n",
    "        返回值\n",
    "        -----\n",
    "        result:数组，装载了清洗得到的目标内容，如何ip、端口号以及其他信息\n",
    "        '''\n",
    "        result = []\n",
    "        for i in soup.select(\"#ip_list .odd\"):  #遍历每一组信息\n",
    "            string = \"\"                         #初始化空字符\n",
    "            for j in i.select(\"td\"):           #信息存在td标签的text中\n",
    "                if j.text.strip()!='':         #过滤掉没有text的td标签\n",
    "                    info = j.text.strip()      #去除两边的空字符\n",
    "                    string = string + info + \"|\"\n",
    "\n",
    "            for m in i.select(\".bar\"):      #反应速度和连接时长都在此处\n",
    "                time = m[\"title\"]           #反应时间和连接时间\n",
    "                string = string+time+\"|\"    #\n",
    "            result.append(string)           #保存每一组的string\n",
    "        return result\n",
    "\n",
    "    def get_ip_form(self,result=None):\n",
    "        '''\n",
    "        功能：对获取的ip信息进行整合成符合requests的形式\n",
    "\n",
    "        参数\n",
    "        ----\n",
    "        result：数组，装载了清洗得到的目标内容，如何ip、端口号以及其他信息\n",
    "\n",
    "        返回值\n",
    "        -----\n",
    "        ip_list:数组，获取新的ip组\n",
    "\n",
    "        '''\n",
    "        ip_list = []                  #用来装整合的ip\n",
    "        for i in result:              #遍历每一条ip信息\n",
    "            if 'sock' not in i:       #删选socket类的代理ip\n",
    "                a = i.split(\"|\")      #分割\n",
    "                type1 = a[4].lower() #将代理ip的类型全部变成小写\n",
    "                ip = a[0]            #ip号\n",
    "                port=a[1]            #代理ip端口\n",
    "                ip_list.append([type1,type1+\"://\"+ip+\":\"+port]) #添加整合好的ip记录\n",
    "        return ip_list\n",
    "\n",
    "    def check_ip(self,test_url,ip_list=None,timeout=10):\n",
    "        '''\n",
    "        功能：对每一个ip进行测试，返回有效的，提除无效的\n",
    "\n",
    "        参数\n",
    "        ----\n",
    "        ip_list：数组，装载代理ip的类型，代理ip和端口\n",
    "        url：字符串，用来检测ip是否可用的url\n",
    "        timeout:整型，访问时间上限，如果超过该时间限制仍访问不成功，即报错。\n",
    "\n",
    "        返回值\n",
    "        -----\n",
    "        new_ip_list:数组，获取新的ip组\n",
    "\n",
    "        '''\n",
    "        new_ip_list = [] \n",
    "        for i in ip_list:\n",
    "            proxies = {i[0]:i[1]}\n",
    "            try:\n",
    "                if '天' not in i[1]and not self.check_chinese(i[1]):\n",
    "                    res = requests.get(test_url,proxies=proxies,timeout=timeout)\n",
    "                    new_ip_list.append(i)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(\"坏ip:\",i)\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                return new_ip_list\n",
    "        return new_ip_list\n",
    "\n",
    "    def get_ip_pool(self,test_url=\"https://music.163.com/\",timeout = 3):\n",
    "        timeout = timeout\n",
    "        ip_pool = []\n",
    "        for ip_url in self.ip_url_ls:\n",
    "            print(ip_url)\n",
    "            soup = self.visit_url(ip_url) ##访问西刺网\n",
    "            result = self.get_iplist(soup) #获取第一页的ip结果\n",
    "            ip_list = self.get_ip_form(result) #获取ip形式\n",
    "            new_ip_list = self.check_ip(test_url,ip_list,timeout) #检查ip\n",
    "            ip_pool.extend(new_ip_list)\n",
    "        return ip_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
