{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from IPpool.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import os.path\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException,WebDriverException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from requests.exceptions import ProxyError,ConnectionError,Timeout,HTTPError,ChunkedEncodingError\n",
    "import itertools\n",
    "import multiprocessing\n",
    "from IPpool import GetHeaders\n",
    "from IPpool import Ip_pool\n",
    "import random\n",
    "import copy\n",
    "import os\n",
    "# import requests_toolbelt.adapters.appengine\n",
    "\n",
    "# requests_toolbelt.adapters.appengine.monkeypatch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requests_visit_url_test(url,is_use_ip =False,timeout=5):\n",
    "        global ip_pool\n",
    "        global bad_ip\n",
    "        #headers = {\"User-Agent\":\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/61.0.3163.100 Chrome/61.0.3163.100 Safari/537.36\"}\n",
    "        headers = {'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "                    'Accept-Encoding':'gzip, deflate',\n",
    "                    'Accept-Language':'zh-CN,zh;q=0.8,en;q=0.6',\n",
    "                    'Cache-Control':'max-age=0',\n",
    "                    'Connection':'keep-alive',\n",
    "                    'Cookie':'_hc.v=f72dbe69-bcfc-a9d4-1f7f-d8daeca1ad7f.1505634421; _lxsdk_cuid=15e956d9d5ec8-0a28c942cf39be-2a044871-100200-15e956d9d5fc8; _lxsdk=15e956d9d5ec8-0a28c942cf39be-2a044871-100200-15e956d9d5fc8; __mta=222713764.1505836341840.1507819135553.1507819166825.4; wed_user_path=163|0; Hm_lvt_dbeeb675516927da776beeb1d9802bd4=1508317369; __utma=1.1801105885.1505634423.1505636820.1508318009.3; __utmz=1.1505634423.1.1.utmcsr=google.com.hk|utmccn=(referral)|utmcmd=referral|utmcct=/; _lx_utm=utm_source%3Dgoogle%26utm_medium%3Dorganic; JSESSIONID=E0D0810114F31617ED97BC416CFDCE80; aburl=1; cy=1; cye=shanghai; _lx_utm=utm_source%3Dgoogle%26utm_medium%3Dorganic; s_ViewType=10; _lxsdk_s=15f304e1839-37c-2e4-6cf%7C%7C174',                    'Host':'www.dianping.com',\n",
    "                    'If-Modified-Since':'Wed, 18 Oct 2017 08:58:29 GMT',\n",
    "                    'Referer':'http://www.dianping.com/search/category/219/30/g141',\n",
    "                    'Upgrade-Insecure-Requests':'1',\n",
    "                    'User-Agent':random.choice(GetHeaders().user_agent_list)}\n",
    "\n",
    "        #获取任意一个请求头\n",
    "        #headers[\"User-Agent\"] = random.choice(GetHeaders().user_agent_list)\n",
    "        bad_ip = []  #用来装坏的ip\n",
    "        \n",
    "        #*********如果不设置ip的话**********************************\n",
    "        if is_use_ip == False:\n",
    "            res = requests.get(url,headers = headers,timeout=timeout)  #访问url，不设代理ip访问\n",
    "            html =  res.content.decode('utf-8')\n",
    "            soup  =  BeautifulSoup(html,'lxml')\n",
    "            if soup.title.text == '403 Forbidden' or \"有道\" in soup.title.text:\n",
    "                print(\"ip被禁止了！！！！！！！！！！！！！！！！\")\n",
    "                raise ConnectionError\n",
    "           \n",
    "        #************如果设置ip的话，则执行这一段*********************\n",
    "        else:\n",
    "            is_continue = True   #设置循环标志\n",
    "            while is_continue:\n",
    "            #整理成ip地址的格式\n",
    "                try:\n",
    "                    #\n",
    "                    print(len(bad_ip))\n",
    "                    if len(ip_pool)==len(bad_ip):\n",
    "                        ip_url = ['http://www.xicidaili.com/nn/']\n",
    "                        test_url = 'http://www.dianping.com/'\n",
    "                        ip_pool= Ip_pool().get_ip_pool(test_url,timeout=2)\n",
    "                        prox_ip = random.choice(ip_pool)\n",
    "                        bad_ip = []\n",
    "                        \n",
    "                    #******随机生成一个ip*******\n",
    "                    prox_ip = random.choice(ip_pool)\n",
    "                    http = prox_ip[0]\n",
    "                    ip = prox_ip[1]\n",
    "                    proxies={http:ip}\n",
    "                    print(proxies)\n",
    "                    \n",
    "                    #*******用代理ip访问********\n",
    "                    res = requests.get(url,headers = headers,proxies = proxies,timeout=timeout) #设代理ip访问\n",
    "                    html =  res.content.decode('utf-8')\n",
    "                    soup  =  BeautifulSoup(html,'lxml')\n",
    "                    \n",
    "                    \n",
    "                    #********如果返回网页被禁止的情况，触发异常,否则返回正常**********\n",
    "                    if  soup.title.text == '403 Forbidden' or \"有道\" in soup.title.text:\n",
    "                        print(\"ip被禁止了!!!!!!!!!!!!!!!!!!!!\")\n",
    "                        raise ConnectionError\n",
    "                    else:\n",
    "                        is_continue = False\n",
    "\n",
    "                except HTTPError as e:\n",
    "                    bad_ip.append(prox_ip)\n",
    "                    print(\"断网\")\n",
    "                    prox_ip = random.choice(ip_pool)\n",
    "                    time.sleep(2)\n",
    "\n",
    "\n",
    "                except Timeout as e:\n",
    "                    bad_ip.append(prox_ip)\n",
    "                    print(\"超时\")\n",
    "                    prox_ip = random.choice(ip_pool)\n",
    "                    time.sleep(2)\n",
    "\n",
    "\n",
    "                except ConnectionError as e:\n",
    "                    bad_ip.append(prox_ip)\n",
    "                    print(\"访问被拒\")\n",
    "                    prox_ip = random.choice(ip_pool)\n",
    "                    time.sleep(2)\n",
    "                    \n",
    "                except AttributeError as e:\n",
    "                    bad_ip.append(prox_ip)\n",
    "                    print(\"----------\")\n",
    "                    prox_ip = random.choice(ip_pool)\n",
    "                    time.sleep(2)\n",
    "\n",
    "        return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**************将装机地址变成一组一组*****************\n",
    "def get_chunk(adr_ls,n):\n",
    "    new_adr_ls = copy.deepcopy(adr_ls)\n",
    "    adr_chunk = [new_adr_ls[i:i + n] for i in range(0, len(new_adr_ls), n)]\n",
    "    return adr_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#缓存结果\n",
    "def save_cache(result,filename):\n",
    "    with open(filename,'wb') as f1:\n",
    "        pickle.dump(result,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载缓存\n",
    "def read_cache(filename):\n",
    "    with open(filename,'rb')as f1:\n",
    "        result = pickle.load(f1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切换路径\n",
    "def get_spc_path(father_path,child_path):\n",
    "    os.chdir(father_path)\n",
    "    if os.path.exists(child_path):\n",
    "        os.chdir(child_path)\n",
    "    else:\n",
    "        os.mkdir(child_path)\n",
    "        os.chdir(child_path)\n",
    "    print(\"done!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
